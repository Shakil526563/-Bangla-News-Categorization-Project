{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"gpuClass":"standard","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1576225,"sourceType":"datasetVersion","datasetId":258862}],"dockerImageVersionId":30581,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"id":"ttM2T6RbQ6zh","outputId":"3c2d0f7c-9380-4a6d-98e0-45ec5daa1029","execution":{"iopub.status.busy":"2023-11-17T16:43:41.753873Z","iopub.execute_input":"2023-11-17T16:43:41.754367Z","iopub.status.idle":"2023-11-17T16:43:42.147328Z","shell.execute_reply.started":"2023-11-17T16:43:41.754340Z","shell.execute_reply":"2023-11-17T16:43:42.146438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# New Section","metadata":{"id":"7H3oh_koCwki"}},{"cell_type":"code","source":"import json\nwith open(file='/kaggle/input/data_v2/data_v2.json', encoding='utf-8') as file:\n    data=json.load(file)\n","metadata":{"id":"rguiXtnKRFc9","execution":{"iopub.status.busy":"2023-11-17T16:43:42.149275Z","iopub.execute_input":"2023-11-17T16:43:42.150159Z","iopub.status.idle":"2023-11-17T16:44:35.792030Z","shell.execute_reply.started":"2023-11-17T16:43:42.150123Z","shell.execute_reply":"2023-11-17T16:44:35.791247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\n\n\ntokenizer = Tokenizer(num_words = 1000)   #maximum word limit 1000\ntokenizer.fit_on_texts(data[6]['content']) # fit sentence\n","metadata":{"id":"U4DLxR8DRYSE","execution":{"iopub.status.busy":"2023-11-17T16:44:35.793354Z","iopub.execute_input":"2023-11-17T16:44:35.793714Z","iopub.status.idle":"2023-11-17T16:44:46.658803Z","shell.execute_reply.started":"2023-11-17T16:44:35.793670Z","shell.execute_reply":"2023-11-17T16:44:46.657932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.get_config()","metadata":{"id":"MjY06HNDRbvO","outputId":"600c7eca-d1f2-4c2d-a73b-7714c62fb70e","execution":{"iopub.status.busy":"2023-11-17T16:44:46.660859Z","iopub.execute_input":"2023-11-17T16:44:46.661375Z","iopub.status.idle":"2023-11-17T16:44:46.668797Z","shell.execute_reply.started":"2023-11-17T16:44:46.661349Z","shell.execute_reply":"2023-11-17T16:44:46.667814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy.lib.arraysetops import unique\n\ncategory_list = []\nfilterData = []\ngarbageCategory = []\ngarbageContent = []\nfor i in range(len(data)):\n    category = data[i]['category']\n    category_list.append(category);\n    if category == '-1' or category == '22221' or category == 'we-are' :\n      garbageCategory.append(data[i])\n      continue\n    if data[i]['content'] == '-1' :\n      garbageContent.append(data[i])\n      continue\n    filterData.append(data[i])\n\nprint(len(garbageCategory))\nprint(len(garbageCategory))\nlen(filterData)","metadata":{"id":"GMhWVfb8Rk02","outputId":"88961146-ce28-47af-9176-cc1c795ee59d","execution":{"iopub.status.busy":"2023-11-17T16:44:46.670041Z","iopub.execute_input":"2023-11-17T16:44:46.670574Z","iopub.status.idle":"2023-11-17T16:44:47.096216Z","shell.execute_reply.started":"2023-11-17T16:44:46.670539Z","shell.execute_reply":"2023-11-17T16:44:47.095357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nnew_category_list = []\n\nfor i in range(len(filterData)):\n    new_category_list.append(filterData[i]['category'])\n\n\nunique_category_list = np.unique(np.array(new_category_list))\nprint(len(unique_category_list))\nprint(unique_category_list)\n","metadata":{"id":"5pj3g_-vRm1v","outputId":"47873a50-63de-44af-8813-d5fe57fe74ea","execution":{"iopub.status.busy":"2023-11-17T16:44:47.097408Z","iopub.execute_input":"2023-11-17T16:44:47.097799Z","iopub.status.idle":"2023-11-17T16:44:47.453192Z","shell.execute_reply.started":"2023-11-17T16:44:47.097768Z","shell.execute_reply":"2023-11-17T16:44:47.452269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\nCounter(new_category_list)","metadata":{"id":"7c4KLYQ6Rsv_","outputId":"0ae9ac71-204f-42b7-af9b-54639e8de0b0","execution":{"iopub.status.busy":"2023-11-17T16:44:47.455221Z","iopub.execute_input":"2023-11-17T16:44:47.455945Z","iopub.status.idle":"2023-11-17T16:44:47.507941Z","shell.execute_reply.started":"2023-11-17T16:44:47.455910Z","shell.execute_reply":"2023-11-17T16:44:47.506999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncategory_count = []\nfor each_category in unique_category_list:\n    count_of_each_category = category_list.count(each_category)\n    category_count.append((each_category,count_of_each_category))\n\ncategory_count.sort();\ncategory_count\n","metadata":{"id":"2AueNkf6Rths","outputId":"b6f932ec-b87c-4c5c-aece-96482462dca0","execution":{"iopub.status.busy":"2023-11-17T16:45:11.997727Z","iopub.execute_input":"2023-11-17T16:45:11.998120Z","iopub.status.idle":"2023-11-17T16:45:12.143331Z","shell.execute_reply.started":"2023-11-17T16:45:11.998091Z","shell.execute_reply":"2023-11-17T16:45:12.142435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_category_list = []\n\nfor i in category_count:\n     if( i[1] > 2500 ):\n         selected_category_list.append(i[0])\n\nprint(len(selected_category_list))\nselected_category_list","metadata":{"id":"rWXbgvp6Rv91","outputId":"794f5ded-a7a1-420e-b981-846cd5b039cd","execution":{"iopub.status.busy":"2023-11-17T16:45:14.422237Z","iopub.execute_input":"2023-11-17T16:45:14.422610Z","iopub.status.idle":"2023-11-17T16:45:14.429998Z","shell.execute_reply.started":"2023-11-17T16:45:14.422579Z","shell.execute_reply":"2023-11-17T16:45:14.429023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfeatures = []\ntarget = []\n\n\nfor i in filterData:\n    if i['category'] in selected_category_list:\n        if target.count(i['category']) < 8000:\n          features.append(i['content'])\n          target.append(i['category'])\n\n\nprint(len(features))\nprint(len(target))\n\n# Check dataset\nprint(\"Category: --\",target[-1])\nprint(\"Content: --\",features[-1])\n","metadata":{"id":"WpWfFGA9Rzkw","outputId":"dae74136-014a-4e69-b8a3-4aa36daee9a8","execution":{"iopub.status.busy":"2023-11-17T16:45:17.037954Z","iopub.execute_input":"2023-11-17T16:45:17.038587Z","iopub.status.idle":"2023-11-17T16:55:11.040697Z","shell.execute_reply.started":"2023-11-17T16:45:17.038553Z","shell.execute_reply":"2023-11-17T16:55:11.039576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install bnlp_toolkit\n# !pip install git+https://github.com/banglakit/lemmatizer.git#egg=banglakit-lemmatizer\n\n# from bnlp import NLTKTokenizer\n# from banglakit import lemmatizer as lem\n# from banglakit.lemmatizer import BengaliLemmatizer\n\n# import nltk\n# from nltk.stem import WordNetLemmatizer\n\n# nltk_tokenizer = NLTKTokenizer()\n# lemmatizer = BengaliLemmatizer()\n\n# # text = \"আমার সোনার বাংলা, আমি তোমায় ভালবাসি।\"\n# # tokens = nltk_tokenizer.word_tokenize(text)\n# # lemmatized_text = [lemmatizer.lemmatize(token) for token in tokens]\n\n\n# # Tokenize the list of text.\n# tokens_list = [nltk_tokenizer.word_tokenize(content) for content in features]\n\n# # Apply lemmatization to each token in each list.\n# lemmatized_tokens_list = []\n# for tokens in tokens_list:\n#     lemmatized_tokens = []\n#     for token in tokens:\n#         lemmatized_tokens.append(lemmatizer.lemmatize(token))\n#     lemmatized_tokens_list.append(lemmatized_tokens)\n\n# # Join the tokens back into a single string for each text in the list.\n# # lemmatized_text_list = [' '.join(tokens) for tokens in lemmatized_tokens_list]\n\n","metadata":{"id":"tBZlTsleR2xD","outputId":"33626752-9637-4f2a-b5ee-a5db6438176e","execution":{"iopub.status.busy":"2023-11-15T15:04:08.087298Z","iopub.execute_input":"2023-11-15T15:04:08.087558Z","iopub.status.idle":"2023-11-15T15:04:08.091624Z","shell.execute_reply.started":"2023-11-15T15:04:08.087533Z","shell.execute_reply":"2023-11-15T15:04:08.091021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\nen_target=le.fit_transform(target)\n\nset(en_target)\n","metadata":{"id":"ARHdT3ySR7jj","outputId":"6ac8db68-7c3a-4010-e73c-c30f98d441f1","execution":{"iopub.status.busy":"2023-11-17T16:55:11.042980Z","iopub.execute_input":"2023-11-17T16:55:11.043747Z","iopub.status.idle":"2023-11-17T16:55:11.379253Z","shell.execute_reply.started":"2023-11-17T16:55:11.043709Z","shell.execute_reply":"2023-11-17T16:55:11.378387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, en_target, \n                                                    train_size=0.8,\n                                                    test_size=0.2,\n                                                    random_state=100)\n\n\nprint(len(X_train))\nprint(len(X_test))","metadata":{"id":"2NcxTjSUR-pY","outputId":"dc2269df-cfb0-4bf7-c9f8-3fb332e49621","execution":{"iopub.status.busy":"2023-11-17T16:55:11.380509Z","iopub.execute_input":"2023-11-17T16:55:11.380827Z","iopub.status.idle":"2023-11-17T16:55:11.494154Z","shell.execute_reply.started":"2023-11-17T16:55:11.380788Z","shell.execute_reply":"2023-11-17T16:55:11.493301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import LabelEncoder\n\nvectorizer = CountVectorizer()\nX_train = vectorizer.fit_transform(X_train)\nX_test = vectorizer.transform(X_test)\n\n# Label encode the class labels\nlabel_encoder = LabelEncoder()\ny_train = label_encoder.fit_transform(y_train)\ny_test = label_encoder.transform(y_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T16:55:11.495702Z","iopub.execute_input":"2023-11-17T16:55:11.495973Z","iopub.status.idle":"2023-11-17T16:55:36.357427Z","shell.execute_reply.started":"2023-11-17T16:55:11.495950Z","shell.execute_reply":"2023-11-17T16:55:36.356607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.metrics import precision_recall_fscore_support\n\n# Create and fit the model with different alpha values\nalphas = [0.1, 0.5, 1.0, 1.5]  # Add more alpha values if needed\n\nfor alpha in alphas:\n    nb = MultinomialNB(alpha=alpha)\n    nb.fit(X_train, y_train)\n    predictions = nb.predict(X_test)\n\n    # Evaluate and print the results\n    print(f\"Alpha: {alpha}\")\n    print(\"Confusion Matrix:\")\n    print(confusion_matrix(y_test, predictions))\n    \n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, predictions))\n    \n    # Extract precision, recall, and F1-score separately\n    precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, predictions, average='weighted')\n    \n    # Calculate accuracy\n    acc = accuracy_score(y_test, predictions)\n    \n    print(\"\\nMetrics:\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1_score:.4f}\")\n    print(f\"Accuracy: {acc:.4f}\")\n    print(\"\\n------------------------\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T16:55:46.202162Z","iopub.execute_input":"2023-11-17T16:55:46.202545Z","iopub.status.idle":"2023-11-17T16:55:46.831433Z","shell.execute_reply.started":"2023-11-17T16:55:46.202515Z","shell.execute_reply":"2023-11-17T16:55:46.830464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.metrics import precision_recall_fscore_support\n\n# Assuming X_train, X_test, y_train, y_test are defined\n\n# Train XGBoost model\nxgb = XGBClassifier(objective='binary:logistic', learning_rate=0.5, max_depth=20, n_estimators=500)\nxgb.fit(X_train, y_train)\nxgb_pred = xgb.predict(X_test)\n\n# Evaluate and print the results\nprint(\"XGBoost Model Metrics:\")\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, xgb_pred))\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, xgb_pred))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T16:56:27.650335Z","iopub.execute_input":"2023-11-17T16:56:27.651103Z","iopub.status.idle":"2023-11-17T17:08:27.620587Z","shell.execute_reply.started":"2023-11-17T16:56:27.651072Z","shell.execute_reply":"2023-11-17T17:08:27.619244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n\n# Assuming y_test and xgb_pred are defined\n\n# Extract precision, recall, and F1-score separately\nprecision, recall, f1_score, _ = precision_recall_fscore_support(y_test, xgb_pred, average='weighted')\n\n# Calculate accuracy\nacc = accuracy_score(y_test, xgb_pred)\n\nprint(\"\\nMetrics:\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1_score:.4f}\")\nprint(f\"Accuracy: {acc:.4f}\")\nprint(\"\\n------------------------\\n\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T17:12:24.641384Z","iopub.execute_input":"2023-11-17T17:12:24.641792Z","iopub.status.idle":"2023-11-17T17:12:24.659799Z","shell.execute_reply.started":"2023-11-17T17:12:24.641762Z","shell.execute_reply":"2023-11-17T17:12:24.658843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.metrics import precision_recall_fscore_support\n\n# Assuming X_train, X_test, y_train, y_test are defined\n\n# Train RandomForest model\nrf = RandomForestClassifier(n_estimators=450, criterion='entropy')\nrf.fit(X_train, y_train)\nrf_pred = rf.predict(X_test)\n\n# Evaluate and print the results\nprint(\"RandomForest Model Metrics:\")\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, rf_pred))\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, rf_pred))\n\n# Extract precision, recall, and F1-score separately\nprecision, recall, f1_score, _ = precision_recall_fscore_support(y_test, rf_pred, average='weighted')\n\n# Calculate accuracy\nacc = accuracy_score(y_test, rf_pred)\n\nprint(\"\\nMetrics:\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1_score:.4f}\")\nprint(f\"Accuracy: {acc:.4f}\")\nprint(\"\\n------------------------\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T17:13:36.304691Z","iopub.execute_input":"2023-11-17T17:13:36.305128Z","iopub.status.idle":"2023-11-17T17:35:15.750026Z","shell.execute_reply.started":"2023-11-17T17:13:36.305100Z","shell.execute_reply":"2023-11-17T17:35:15.749040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.metrics import precision_recall_fscore_support\n\n# Assuming X_train, X_test, y_train, y_test are defined\n\n# Train Logistic Regression model\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\nlr_pred = lr.predict(X_test)\n\n# Evaluate and print the results\nprint(\"Logistic Regression Model Metrics:\")\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, lr_pred))\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, lr_pred))\n\n# Extract precision, recall, and F1-score separately\nprecision, recall, f1_score, _ = precision_recall_fscore_support(y_test, lr_pred, average='weighted')\n\n# Calculate accuracy\nacc = accuracy_score(y_test, lr_pred)\n\nprint(\"\\nMetrics:\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1_score:.4f}\")\nprint(f\"Accuracy: {acc:.4f}\")\nprint(\"\\n------------------------\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T17:41:09.690323Z","iopub.execute_input":"2023-11-17T17:41:09.691219Z","iopub.status.idle":"2023-11-17T17:41:46.466594Z","shell.execute_reply.started":"2023-11-17T17:41:09.691183Z","shell.execute_reply":"2023-11-17T17:41:46.465582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.metrics import precision_recall_fscore_support\n\n# A\n# Train SVM model\nsvm = SVC()\nsvm.fit(X_train, y_train)\nsvm_pred = svm.predict(X_test)\n\n# Evaluate SVM model\nprecision, recall, f1_score, _ = precision_recall_fscore_support(y_test, svm_pred, average='weighted')\nsvm_acc = accuracy_score(y_test, svm_pred)\n\nprint(\"SVM Model Metrics:\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1_score:.4f}\")\nprint(f\"Accuracy: {svm_acc:.4f}\")\nprint(\"\\n------------------------\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-11-17T17:44:12.739768Z","iopub.execute_input":"2023-11-17T17:44:12.740179Z","iopub.status.idle":"2023-11-17T18:09:41.569961Z","shell.execute_reply.started":"2023-11-17T17:44:12.740151Z","shell.execute_reply":"2023-11-17T18:09:41.568879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Assuming X_train, X_test, y_train, y_test are defined\n\n# Train Gradient Boosting Classifier model\ngb = GradientBoostingClassifier()\ngb.fit(X_train, y_train)\n\n# Accuracy score, confusion matrix, and classification report of Gradient Boosting Classifier\ngb_acc = accuracy_score(y_test, gb.predict(X_test))\n\nprint(f\"Training Accuracy of Gradient Boosting Classifier is {accuracy_score(y_train, gb.predict(X_train))}\")\nprint(f\"Test Accuracy of Gradient Boosting Classifier is {gb_acc} \\n\")\n\n# Confusion matrix\ncm = confusion_matrix(y_test, gb.predict(X_test))\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix - Gradient Boosting Classifier')\nplt.show()\n\n# Classification report\nclassification_rep = classification_report(y_test, gb.predict(X_test))\nprint(f\"Classification Report :- \\n{classification_rep}\\n\")\n\n# Extract precision, recall, and F1-score separately\nprecision, recall, f1_score, _ = precision_recall_fscore_support(y_test, gb.predict(X_test), average='weighted')\n\n# Print precision, recall, and F1-score\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1_score:.4f}\")\n\n# Compare accuracies and print the best model\nbest_model = max([('Gradient Boosting Classifier', gb_acc)], key=lambda x: x[1])\nprint(f\"The best model is {best_model[0]} with an accuracy of {best_model[1]:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T18:14:48.650106Z","iopub.execute_input":"2023-11-17T18:14:48.650890Z","iopub.status.idle":"2023-11-17T18:30:48.186390Z","shell.execute_reply.started":"2023-11-17T18:14:48.650857Z","shell.execute_reply":"2023-11-17T18:30:48.185461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nnb = MultinomialNB()\nnb.fit(X_train, y_train)\nMultinomialNB(alpha=0.5, class_prior=None, fit_prior=True)\npredictions = nb.predict(X_test)\nfrom sklearn.metrics import confusion_matrix, classification_report\nprint(confusion_matrix(y_test, predictions))\nprint(classification_report(y_test, predictions))","metadata":{"execution":{"iopub.status.busy":"2023-11-17T16:56:13.501620Z","iopub.execute_input":"2023-11-17T16:56:13.501999Z","iopub.status.idle":"2023-11-17T16:56:13.645623Z","shell.execute_reply.started":"2023-11-17T16:56:13.501971Z","shell.execute_reply":"2023-11-17T16:56:13.644755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:09:24.306805Z","iopub.execute_input":"2023-11-15T15:09:24.307149Z","iopub.status.idle":"2023-11-15T15:09:24.331214Z","shell.execute_reply.started":"2023-11-15T15:09:24.307121Z","shell.execute_reply":"2023-11-15T15:09:24.330435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:15:46.733402Z","iopub.execute_input":"2023-11-15T15:15:46.733793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-11-15T04:59:10.735378Z","iopub.execute_input":"2023-11-15T04:59:10.735751Z","iopub.status.idle":"2023-11-15T07:46:24.907931Z","shell.execute_reply.started":"2023-11-15T04:59:10.735723Z","shell.execute_reply":"2023-11-15T07:46:24.905746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\n# Perform cross-validation\ncv_scores = cross_val_score(xgb, X_train, y_train, cv=5, scoring='accuracy')\n\n# Print cross-validation scores\nprint(\"Cross-Validation Scores:\", cv_scores)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:46:25.179770Z","iopub.execute_input":"2023-11-15T07:46:25.180516Z","iopub.status.idle":"2023-11-15T07:46:25.217782Z","shell.execute_reply.started":"2023-11-15T07:46:25.180482Z","shell.execute_reply":"2023-11-15T07:46:25.216721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\n# Assuming X_train, X_test, y_train, y_test are defined\n\n# Train XGBoost model\nxgb = XGBClassifier(objective='binary:logistic', learning_rate=0.5, max_depth=20, n_estimators=500)\nxgb.fit(X_train, y_train)\nxgb_pred = xgb.predict(X_test)\n\n# Train RandomForest model\nrf = RandomForestClassifier(n_estimators=450, criterion='entropy')\nrf.fit(X_train, y_train)\nrf_pred = rf.predict(X_test)\n\n# Combine predictions using weighted average\ncombined_pred = 0.7 * xgb_pred + 0.3 * rf_pred  # You can experiment with different weights\n\n# Convert combined predictions to binary\ncombined_pred_binary = [1 if pred >= 0.5 else 0 for pred in combined_pred]\n\n# Evaluate the combined model\ncombined_acc = accuracy_score(y_test, combined_pred_binary)\n\nprint(f\"XGBoost Accuracy: {accuracy_score(y_test, xgb_pred)}\")\nprint(f\"RandomForest Accuracy: {accuracy_score(y_test, rf_pred)}\")\nprint(f\"Combined Model Accuracy: {combined_acc}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:46:41.214805Z","iopub.execute_input":"2023-11-15T07:46:41.215722Z","iopub.status.idle":"2023-11-15T07:59:44.025285Z","shell.execute_reply.started":"2023-11-15T07:46:41.215690Z","shell.execute_reply":"2023-11-15T07:59:44.024311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install xgboost\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:15:17.287692Z","iopub.execute_input":"2023-11-15T15:15:17.288026Z","iopub.status.idle":"2023-11-15T15:15:38.701915Z","shell.execute_reply.started":"2023-11-15T15:15:17.287993Z","shell.execute_reply":"2023-11-15T15:15:38.700799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-11-15T12:38:34.818238Z","iopub.execute_input":"2023-11-15T12:38:34.819036Z","iopub.status.idle":"2023-11-15T12:38:36.847607Z","shell.execute_reply.started":"2023-11-15T12:38:34.818999Z","shell.execute_reply":"2023-11-15T12:38:36.846857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#from pandas_profiling import ProfileReport\n\n%matplotlib inline\nimport pandas as pd \nimport numpy as np \nimport seaborn as sns \nimport matplotlib.pyplot as plt \n#from pandas_profiling import ProfileReport\nimport math\n\n#from statsmodels.stats.outliers_influence import variance_inflation_factor\n#from statsmodels.tools.tools import add_constant  \n#from statsmodels.stats.outliers_influence import variance_inflation_factor\n#from statsmodels.tools.tools import add_constant  \nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.datasets import make_classification\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.model_selection import train_test_split\n#from imblearn.over_sampling import SMOTE\n\n#from sklearn.metrics import confusion_matrix,plot_roc_curve, classification_report\nfrom sklearn.metrics import mean_absolute_error , mean_absolute_percentage_error , mean_squared_error , accuracy_score\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.svm import SVC\nfrom sklearn.impute import KNNImputer\nfrom xgboost import XGBClassifier\n#from catboost import CatBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-11-15T12:37:09.054992Z","iopub.execute_input":"2023-11-15T12:37:09.055873Z","iopub.status.idle":"2023-11-15T12:37:09.095744Z","shell.execute_reply.started":"2023-11-15T12:37:09.055808Z","shell.execute_reply":"2023-11-15T12:37:09.094934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\ntr= RandomForestClassifier(n_estimators= 450, criterion=\"entropy\")  \ntr.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T18:26:16.512202Z","iopub.execute_input":"2023-11-14T18:26:16.512602Z","iopub.status.idle":"2023-11-14T18:29:27.675004Z","shell.execute_reply.started":"2023-11-14T18:26:16.512568Z","shell.execute_reply":"2023-11-14T18:29:27.674093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ny_pred= tr.predict(X_test)  \nfrom sklearn.metrics import confusion_matrix  \ncm= confusion_matrix(y_test, y_pred)  \n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T18:29:27.676503Z","iopub.execute_input":"2023-11-14T18:29:27.676766Z","iopub.status.idle":"2023-11-14T18:29:28.922416Z","shell.execute_reply.started":"2023-11-14T18:29:27.676740Z","shell.execute_reply":"2023-11-14T18:29:28.921593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install seaborn\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T12:36:29.752617Z","iopub.execute_input":"2023-11-15T12:36:29.753388Z","iopub.status.idle":"2023-11-15T12:36:34.362890Z","shell.execute_reply.started":"2023-11-15T12:36:29.753349Z","shell.execute_reply":"2023-11-15T12:36:34.361779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure()\n#cf_matrix = confusion_matrix(y_test, model.predict(X_test))\n#plt.title('Confusion Matrix: {}'.format(name))\ncolormap = sns.color_palette(\"Blues\",30)\n\nsns.heatmap(cm, annot = True, fmt = 'g', cmap = 'crest')\nplt.show()\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T18:29:32.485721Z","iopub.execute_input":"2023-11-14T18:29:32.486005Z","iopub.status.idle":"2023-11-14T18:29:32.883579Z","shell.execute_reply.started":"2023-11-14T18:29:32.485974Z","shell.execute_reply":"2023-11-14T18:29:32.882880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install scikit-plot\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T12:36:52.775283Z","iopub.execute_input":"2023-11-15T12:36:52.775631Z","iopub.status.idle":"2023-11-15T12:36:56.461484Z","shell.execute_reply.started":"2023-11-15T12:36:52.775598Z","shell.execute_reply":"2023-11-15T12:36:56.460410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import scikitplot as skplt\n\nskplt.metrics.plot_roc(y_test, tr.predict_proba(X_test))\n#plt.title('ROC Curves: {}'.format(name))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T18:29:36.689199Z","iopub.execute_input":"2023-11-14T18:29:36.689463Z","iopub.status.idle":"2023-11-14T18:29:38.345633Z","shell.execute_reply.started":"2023-11-14T18:29:36.689433Z","shell.execute_reply":"2023-11-14T18:29:38.344867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_1 = accuracy_score(y_test,y_pred) * 100\naccuracy_1","metadata":{"execution":{"iopub.status.busy":"2023-11-14T18:29:38.346655Z","iopub.execute_input":"2023-11-14T18:29:38.346925Z","iopub.status.idle":"2023-11-14T18:29:38.353175Z","shell.execute_reply.started":"2023-11-14T18:29:38.346898Z","shell.execute_reply":"2023-11-14T18:29:38.352522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Scaling features between -1 and 1\nscaler = StandardScaler(with_mean=False)  # Pass with_mean=False to avoid centering sparse matrices\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T18:30:35.330476Z","iopub.execute_input":"2023-11-14T18:30:35.330830Z","iopub.status.idle":"2023-11-14T18:30:35.368063Z","shell.execute_reply.started":"2023-11-14T18:30:35.330800Z","shell.execute_reply":"2023-11-14T18:30:35.367315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install mlxtend\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T12:36:47.082880Z","iopub.execute_input":"2023-11-15T12:36:47.083601Z","iopub.status.idle":"2023-11-15T12:36:51.258889Z","shell.execute_reply.started":"2023-11-15T12:36:47.083566Z","shell.execute_reply":"2023-11-15T12:36:51.257745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-11-14T18:33:58.393158Z","iopub.execute_input":"2023-11-14T18:33:58.393478Z","iopub.status.idle":"2023-11-14T18:33:58.397910Z","shell.execute_reply.started":"2023-11-14T18:33:58.393448Z","shell.execute_reply":"2023-11-14T18:33:58.396868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Models to be used for ML\nmodels = [('Logistic Regression', LogisticRegression()),\n          ('Decision Tree Classifier', DecisionTreeClassifier()),\n          ('Random Forest', RandomForestClassifier()),\n          #('Linear Discriminant Analyzer', LinearDiscriminantAnalysis()),\n          ('Ada Boost', AdaBoostClassifier()),\n          ('KNN', KNeighborsClassifier()),\n          \n          ]\n\nmodels_score = []\nfor name, model in models:\n    model = model #Model Object create\n    model.fit(X_train, y_train)\n    model.predict(X_test)\n    models_score.append([name, accuracy_score(y_test, model.predict(X_test))])\n    \n    print(\"Model: \",name)\n    print('Validation Accuracy: ', accuracy_score(y_test, model.predict(X_test)))\n    print('Training Accuracy: ', accuracy_score(y_train, model.predict(X_train)))\n    \n    plt.figure()\n    cf_matrix = confusion_matrix(y_test, model.predict(X_test))\n    #plt.title('Confusion Matrix: {}'.format(name))\n    colormap = sns.color_palette(\"Blues\",30)\n\n    sns.heatmap(cf_matrix, annot = True, fmt = 'g', cmap = 'crest')\n    plt.show()\n    \n    import scikitplot as skplt\n\n    skplt.metrics.plot_roc(y_test, model.predict_proba(X_test))\n    plt.title('ROC Curves: {}'.format(name))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T18:34:00.035435Z","iopub.execute_input":"2023-11-14T18:34:00.036227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"XCj0-qIaOP-b","outputId":"d67b17d9-c341-4cce-ebda-67675567f2f6","execution":{"iopub.status.busy":"2023-02-23T15:32:48.675186Z","iopub.execute_input":"2023-02-23T15:32:48.675523Z","iopub.status.idle":"2023-02-23T16:01:39.615058Z","shell.execute_reply.started":"2023-02-23T15:32:48.675478Z","shell.execute_reply":"2023-02-23T16:01:39.613923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-02-23T16:36:03.545261Z","iopub.execute_input":"2023-02-23T16:36:03.545694Z","iopub.status.idle":"2023-02-23T16:36:04.938642Z","shell.execute_reply.started":"2023-02-23T16:36:03.545659Z","shell.execute_reply":"2023-02-23T16:36:04.937815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-02-23T17:53:09.089745Z","iopub.execute_input":"2023-02-23T17:53:09.091047Z","iopub.status.idle":"2023-02-23T17:53:09.110168Z","shell.execute_reply.started":"2023-02-23T17:53:09.090999Z","shell.execute_reply":"2023-02-23T17:53:09.108606Z"},"trusted":true},"execution_count":null,"outputs":[]}]}